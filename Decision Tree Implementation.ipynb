{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'student', b'spend>saving', 6.0, 40.0, 13.62, 3.2804, b'C1'], [b'student', b'spend>saving', 11.0, 21.0, 15.32, 2.0232, b'C1'], [b'student', b'spend>saving', 7.0, 64.0, 16.55, 3.1202, b'C1'], [b'student', b'spend>saving', 3.0, 47.0, 15.71, 3.4022, b'C1'], [b'student', b'spend>saving', 15.0, 10.0, 16.96, 2.2825, b'C1'], [b'student', b'spend>saving', 6.0, 80.0, 15.5, 3.7338, b'C1'], [b'student', b'spend<saving', 10.0, 49.0, 16.86, 5.8639, b'C1'], [b'student', b'spend<saving', 10.0, 84.0, 14.66, 3.187, b'C1'], [b'student', b'spend<saving', 9.0, 74.0, 13.86, 2.3823, b'C1'], [b'student', b'spend>>saving', 22.0, 38.0, 13.88, 0.7394, b'C1'], [b'student', b'spend>>saving', 25.0, 30.0, 15.64, 3.1282, b'C1'], [b'student', b'spend>>saving', 31.0, 15.0, 14.4, 2.3925, b'C1'], [b'student', b'spend>>saving', 24.0, 55.0, 15.55, 1.9857, b'C1'], [b'student', b'spend>>saving', 28.0, 85.0, 13.9, 4.3147, b'C1'], [b'student', b'spend<<saving', 25.0, 24.0, 15.09, 5.1951, b'C1'], [b'student', b'spend<<saving', 24.0, 15.0, 13.0, 1.6162, b'C1'], [b'student', b'spend<<saving', 25.0, 33.0, 14.51, 2.5551, b'C1'], [b'engineer', b'spend>saving', 23.0, 86.0, 20.04, 1.351, b'C1'], [b'engineer', b'spend>saving', 20.0, 69.0, 19.69, 7.0714, b'C1'], [b'engineer', b'spend>saving', 14.0, 86.0, 20.23, 7.4749, b'C1'], [b'engineer', b'spend>saving', 41.0, 50.0, 21.0, 6.8701, b'C1'], [b'engineer', b'spend>saving', 17.0, 38.0, 21.22, 1.0881, b'C1'], [b'engineer', b'spend>saving', 6.0, 76.0, 19.46, 3.1729, b'C1'], [b'engineer', b'spend>saving', 38.0, 61.0, 20.91, 3.2021, b'C1'], [b'engineer', b'spend>saving', 23.0, 45.0, 19.83, 4.215, b'C1'], [b'engineer', b'spend>saving', 9.0, 58.0, 19.66, 2.4553, b'C1'], [b'engineer', b'spend>>saving', 46.0, 20.0, 20.54, 1.6447, b'C1'], [b'engineer', b'spend>>saving', 53.0, 82.0, 20.93, 2.7064, b'C1'], [b'engineer', b'spend>>saving', 31.0, 40.0, 19.43, 5.7642, b'C1'], [b'engineer', b'spend>>saving', 41.0, 46.0, 18.5, 8.3453, b'C1'], [b'engineer', b'spend<<saving', 39.0, 87.0, 19.95, 4.0586, b'C1'], [b'engineer', b'spend<<saving', 28.0, 42.0, 20.55, 3.0668, b'C1'], [b'engineer', b'spend<<saving', 52.0, 52.0, 20.08, 5.0033, b'C1'], [b'engineer', b'spend<<saving', 40.0, 50.0, 21.58, 2.6248, b'C1'], [b'engineer', b'spend<<saving', 45.0, 92.0, 19.67, 7.325, b'C1'], [b'engineer', b'spend<<saving', 33.0, 62.0, 20.8, 5.8137, b'C1'], [b'librarian', b'spend>saving', 7.0, 10.0, 18.1751, 1.2225, b'C2'], [b'librarian', b'spend>saving', 1.0, 3.0, 16.4385, 0.9869, b'C2'], [b'librarian', b'spend>saving', 2.0, 8.0, 12.4786, 0.7506, b'C2'], [b'librarian', b'spend>saving', 7.0, 11.0, 15.8298, 0.5672, b'C2'], [b'librarian', b'spend>saving', 5.0, 11.0, 14.6699, 1.0147, b'C2'], [b'librarian', b'spend<saving', 7.0, 11.0, 13.4146, 0.1724, b'C2'], [b'librarian', b'spend<saving', 9.0, 10.0, 17.9944, 0.2708, b'C2'], [b'librarian', b'spend<saving', 6.0, 5.0, 11.0413, 1.7063, b'C2'], [b'librarian', b'spend<saving', 3.0, 11.0, 18.254, 0.8712, b'C2'], [b'librarian', b'spend<saving', 7.0, 10.0, 8.8997, 1.9516, b'C2'], [b'librarian', b'spend<saving', 4.0, 11.0, 19.116, 0.8027, b'C2'], [b'librarian', b'spend<saving', 3.0, 12.0, 18.3739, 0.9693, b'C2'], [b'librarian', b'spend>saving', 11.0, 10.0, 20.0328, 1.2693, b'C2'], [b'librarian', b'spend>saving', 5.0, 11.0, 14.2322, 0.8286, b'C2'], [b'professor', b'spend>saving', 10.0, 9.0, 20.5991, 0.552, b'C2'], [b'professor', b'spend>saving', 7.0, 7.0, 8.5076, 1.223, b'C2'], [b'professor', b'spend>saving', 7.0, 11.0, 18.1388, 0.6957, b'C2'], [b'professor', b'spend>saving', 5.0, 14.0, 14.0667, 1.1974, b'C2'], [b'professor', b'spend>saving', 5.0, 8.0, 13.9065, 1.2392, b'C2'], [b'professor', b'spend>saving', 8.0, 8.0, 17.6074, 0.568, b'C2'], [b'professor', b'spend>saving', 4.0, 12.0, 15.6526, 1.1132, b'C2'], [b'professor', b'spend<saving', 3.0, 5.0, 21.054, 1.0448, b'C2'], [b'professor', b'spend<saving', 4.0, 7.0, 15.0986, 0.8853, b'C2'], [b'professor', b'spend<saving', 1.0, 8.0, 17.2758, 0.4089, b'C2'], [b'professor', b'spend<saving', 6.0, 17.0, 18.5944, 0.79, b'C2'], [b'professor', b'spend<saving', 5.0, 11.0, 21.4653, 0.8358, b'C2'], [b'student', b'spend<saving', 6.0, 73.0, 31.75, 4.8256, b'C3'], [b'student', b'spend<saving', 11.0, 71.0, 26.31, 3.4024, b'C3'], [b'student', b'spend<saving', 11.0, 70.0, 27.86, 3.8865, b'C3'], [b'student', b'spend<saving', 7.0, 66.0, 31.39, 3.5978, b'C3'], [b'student', b'spend<saving', 9.0, 69.0, 16.74, 5.4591, b'C3'], [b'student', b'spend<saving', 14.0, 70.0, 22.03, 5.0585, b'C3'], [b'student', b'spend>saving', 12.0, 68.0, 22.79, 4.7536, b'C3'], [b'student', b'spend>saving', 13.0, 72.0, 26.19, 2.6436, b'C3'], [b'student', b'spend>saving', 10.0, 66.0, 20.09, 3.9933, b'C3'], [b'student', b'spend>saving', 5.0, 68.0, 24.24, 3.7744, b'C3'], [b'student', b'spend>saving', 5.0, 71.0, 23.79, 4.6938, b'C3'], [b'student', b'spend>saving', 11.0, 75.0, 28.83, 3.3291, b'C3'], [b'student', b'spend>saving', 8.0, 67.0, 22.87, 4.2798, b'C3'], [b'doctor', b'spend>saving', 12.0, 261.0, 23.07, 12.8549, b'C3'], [b'doctor', b'spend>saving', 6.0, 279.0, 26.98, 8.0012, b'C3'], [b'doctor', b'spend>saving', 11.0, 96.0, 28.88, 9.8281, b'C3'], [b'doctor', b'spend>saving', 12.0, 347.0, 25.94, 10.0092, b'C3'], [b'doctor', b'spend>saving', 11.0, 268.0, 27.58, 12.5953, b'C3'], [b'doctor', b'spend>saving', 7.0, 253.0, 25.39, 6.6154, b'C3'], [b'doctor', b'spend>saving', 9.0, 162.0, 25.05, 7.837, b'C3'], [b'doctor', b'spend>saving', 11.0, 187.0, 24.78, 12.5933, b'C3'], [b'doctor', b'spend>saving', 5.0, 131.0, 22.02, 16.408, b'C3'], [b'doctor', b'spend>saving', 8.0, 137.0, 22.76, 13.0995, b'C3'], [b'doctor', b'spend>saving', 7.0, 155.0, 24.91, 10.6717, b'C3'], [b'doctor', b'spend>saving', 13.0, 229.0, 27.97, 11.8543, b'C3'], [b'doctor', b'spend>saving', 15.0, 292.0, 23.2, 12.2331, b'C3'], [b'doctor', b'spend>saving', 12.0, 267.0, 29.43, 17.8737, b'C3'], [b'doctor', b'spend>saving', 8.0, 175.0, 22.56, 11.7815, b'C3'], [b'doctor', b'spend>saving', 11.0, 91.0, 26.94, 14.8164, b'C3'], [b'doctor', b'spend>saving', 9.0, 212.0, 21.07, 11.7612, b'C3'], [b'doctor', b'spend>saving', 7.0, 163.0, 22.4, 9.5971, b'C3'], [b'doctor', b'spend>saving', 11.0, 111.0, 23.58, 12.9283, b'C3'], [b'doctor', b'spend>saving', 10.0, 222.0, 25.67, 15.1555, b'C3'], [b'doctor', b'spend<saving', 9.0, 187.0, 23.77, 11.4248, b'C3'], [b'doctor', b'spend<saving', 12.0, 179.0, 26.53, 13.3902, b'C3'], [b'doctor', b'spend<saving', 6.0, 190.0, 21.4, 9.2276, b'C3'], [b'doctor', b'spend<saving', 8.0, 191.0, 24.71, 10.051, b'C3'], [b'doctor', b'spend<saving', 9.0, 211.0, 26.34, 13.8687, b'C3'], [b'doctor', b'spend<saving', 13.0, 284.0, 24.11, 7.9947, b'C3'], [b'doctor', b'spend<saving', 15.0, 206.0, 24.5, 15.1431, b'C3'], [b'doctor', b'spend<saving', 14.0, 233.0, 25.54, 14.59, b'C3'], [b'doctor', b'spend<saving', 47.0, 51.0, 18.45, 5.6494, b'C4'], [b'doctor', b'spend<saving', 42.0, 66.0, 19.61, 4.202, b'C4'], [b'doctor', b'spend>saving', 40.0, 78.0, 20.28, 3.6179, b'C4'], [b'doctor', b'spend>saving', 40.0, 61.0, 20.83, 1.9896, b'C4'], [b'doctor', b'spend>saving', 34.0, 86.0, 19.02, 4.8388, b'C4'], [b'doctor', b'spend<saving', 59.0, 53.0, 19.9, 4.2836, b'C4'], [b'doctor', b'spend<saving', 38.0, 88.0, 20.13, 2.8193, b'C4'], [b'doctor', b'spend>saving', 26.0, 60.0, 20.06, 4.131, b'C4'], [b'doctor', b'spend>saving', 37.0, 63.0, 20.37, 5.7345, b'C4'], [b'student', b'spend>>saving', 32.0, 66.0, 20.02, 3.5865, b'C4'], [b'student', b'spend<<saving', 23.0, 68.0, 21.37, 2.2667, b'C4'], [b'student', b'spend>saving', 36.0, 43.0, 20.42, 3.0437, b'C4'], [b'student', b'spend<saving', 25.0, 41.0, 20.07, 4.3556, b'C4'], [b'student', b'spend>saving', 39.0, 56.0, 20.29, 2.6881, b'C4'], [b'student', b'spend<saving', 49.0, 60.0, 20.47, 4.9717, b'C4'], [b'student', b'spend>>saving', 64.0, 84.0, 21.78, 3.8456, b'C4'], [b'student', b'spend<<saving', 45.0, 57.0, 20.26, 3.7188, b'C4'], [b'professor', b'spend>>saving', 44.0, 44.0, 21.51, 2.6675, b'C4'], [b'professor', b'spend<<saving', 51.0, 16.0, 20.32, 2.1608, b'C4'], [b'professor', b'spend>>saving', 44.0, 39.0, 20.8, 1.7196, b'C4'], [b'professor', b'spend<<saving', 53.0, 35.0, 20.58, 2.5493, b'C4'], [b'professor', b'spend>saving', 38.0, 25.0, 21.78, 0.008, b'C4'], [b'professor', b'spend<saving', 41.0, 54.0, 19.06, 3.0132, b'C4'], [b'professor', b'spend>saving', 33.0, 50.0, 19.08, 1.7395, b'C4'], [b'professor', b'spend<saving', 32.0, 38.0, 20.38, 1.4075, b'C4'], [b'professor', b'spend>>saving', 34.0, 30.0, 20.91, 2.4095, b'C4'], [b'librarian', b'spend<<saving', 48.0, 35.0, 20.15, 2.4436, b'C4'], [b'librarian', b'spend>>saving', 41.0, 37.0, 19.8, 2.8195, b'C4'], [b'librarian', b'spend<<saving', 22.0, 24.0, 21.49, 2.7344, b'C4'], [b'librarian', b'spend>>saving', 58.0, 27.0, 19.38, 3.0286, b'C4'], [b'librarian', b'spend<<saving', 47.0, 45.0, 20.81, 1.5505, b'C4'], [b'librarian', b'spend>saving', 25.0, 40.0, 21.93, 1.0924, b'C4'], [b'librarian', b'spend<saving', 36.0, 33.0, 20.4, 1.2062, b'C4'], [b'librarian', b'spend>saving', 42.0, 22.0, 19.14, 1.5377, b'C4'], [b'librarian', b'spend<saving', 32.0, 25.0, 22.43, 3.0428, b'C4'], [b'engineer', b'spend>>saving', 39.0, 62.0, 19.16, 3.9847, b'C4'], [b'engineer', b'spend<<saving', 43.0, 69.0, 20.28, 3.5298, b'C4'], [b'engineer', b'spend>>saving', 50.0, 55.0, 20.82, 3.0217, b'C4'], [b'engineer', b'spend<<saving', 26.0, 49.0, 21.23, 4.0693, b'C4'], [b'engineer', b'spend>>saving', 30.0, 44.0, 19.94, 4.8997, b'C4'], [b'engineer', b'spend<<saving', 34.0, 72.0, 20.65, 5.2348, b'C4'], [b'engineer', b'spend>saving', 42.0, 65.0, 18.23, 2.8972, b'C4'], [b'engineer', b'spend<saving', 53.0, 76.0, 20.06, 4.4073, b'C4'], [b'engineer', b'spend>saving', 59.0, 55.0, 19.24, 2.5725, b'C4'], [b'engineer', b'spend<saving', 47.0, 70.0, 18.31, 4.8945, b'C4'], [b'engineer', b'spend>>saving', 48.0, 63.0, 21.1, 3.6149, b'C4'], [b'engineer', b'spend<<saving', 39.0, 51.0, 21.46, 3.8187, b'C4'], [b'professor', b'spend>saving', 48.0, 5.0, 20.39, 1.7536, b'C5'], [b'professor', b'spend>saving', 51.0, 5.0, 27.6, 2.4567, b'C5'], [b'professor', b'spend>saving', 50.0, 3.0, 23.12, 2.4937, b'C5'], [b'professor', b'spend>saving', 51.0, 3.0, 29.52, 2.3271, b'C5'], [b'professor', b'spend>saving', 50.0, 4.0, 18.8, 2.9932, b'C5'], [b'professor', b'spend>saving', 50.0, 6.0, 19.76, 2.8216, b'C5'], [b'professor', b'spend>saving', 49.0, 7.0, 28.84, 3.96, b'C5'], [b'professor', b'spend>saving', 49.0, 5.0, 19.42, 1.8757, b'C5'], [b'professor', b'spend>saving', 50.0, 3.0, 16.31, 2.5786, b'C5'], [b'professor', b'spend>>saving', 49.0, 5.0, 23.51, 2.7638, b'C5'], [b'professor', b'spend>>saving', 50.0, 5.0, 22.71, 3.3358, b'C5'], [b'professor', b'spend>>saving', 50.0, 3.0, 19.59, 2.9, b'C5'], [b'professor', b'spend>>saving', 50.0, 3.0, 18.03, 2.9419, b'C5'], [b'professor', b'spend>>saving', 51.0, 6.0, 26.76, 2.3879, b'C5'], [b'professor', b'spend>>saving', 49.0, 5.0, 31.55, 2.6485, b'C5'], [b'professor', b'spend>>saving', 49.0, 3.0, 31.06, 2.2395, b'C5'], [b'professor', b'spend>>saving', 50.0, 5.0, 31.2, 2.4223, b'C5'], [b'professor', b'spend>>saving', 50.0, 4.0, 20.92, 2.4508, b'C5'], [b'engineer', b'spend>saving', 50.0, 18.0, 24.01, 0.738, b'C5'], [b'engineer', b'spend>saving', 50.0, 18.0, 21.52, 1.6871, b'C5'], [b'engineer', b'spend>saving', 51.0, 22.0, 21.99, 1.358, b'C5'], [b'engineer', b'spend>saving', 49.0, 22.0, 20.27, 1.2342, b'C5'], [b'engineer', b'spend>saving', 50.0, 22.0, 21.22, 0.534, b'C5'], [b'engineer', b'spend>saving', 51.0, 26.0, 25.94, 0.6948, b'C5'], [b'engineer', b'spend>saving', 50.0, 24.0, 23.87, 1.5738, b'C5'], [b'engineer', b'spend>saving', 52.0, 14.0, 16.54, 1.5569, b'C5'], [b'engineer', b'spend>saving', 50.0, 22.0, 23.09, 1.0051, b'C5'], [b'engineer', b'spend>>saving', 49.0, 21.0, 23.89, 1.5087, b'C5'], [b'engineer', b'spend>>saving', 51.0, 20.0, 13.68, 1.5669, b'C5'], [b'engineer', b'spend>>saving', 49.0, 17.0, 18.79, 2.0525, b'C5'], [b'engineer', b'spend>>saving', 50.0, 23.0, 20.17, 2.3291, b'C5'], [b'engineer', b'spend>>saving', 47.0, 23.0, 22.78, 1.041, b'C5'], [b'engineer', b'spend>>saving', 51.0, 23.0, 25.56, 2.5066, b'C5'], [b'engineer', b'spend>>saving', 51.0, 17.0, 15.63, 1.6754, b'C5'], [b'engineer', b'spend>>saving', 51.0, 13.0, 20.71, 1.4585, b'C5'], [b'engineer', b'spend>>saving', 49.0, 17.0, 19.18, 2.4251, b'C5']]\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = arff.loadarff('trainProdSelection.arff')\n",
    "df = pd.DataFrame(dataset[0])\n",
    "nparray = df.values \n",
    "training_data=[]\n",
    "training_data=nparray.tolist()\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header = [\"Type\", \"LifeStyle\", \"Vacation\",\"eCredit\",\"Salary\",\"Property\",\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_vals(rows, col):\n",
    "    \"\"\"Find the unique values for a column in a dataset.\"\"\"\n",
    "    return set([row[col] for row in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'doctor', b'engineer', b'librarian', b'professor', b'student'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vals(training_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_counts(rows):\n",
    "    \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n",
    "    counts = {}  # a dictionary of label -> count.\n",
    "    for row in rows:\n",
    "        # in our dataset format, the label is always the last column\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'C1': 36, b'C2': 26, b'C3': 41, b'C4': 47, b'C5': 36}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_numeric(value):\n",
    "    \"\"\"Test if a value is numeric.\"\"\"\n",
    "    return isinstance(value, int) or isinstance(value, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_numeric(\"Red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Question:\n",
    "    \"\"\"A Question is used to partition a dataset.\n",
    "\n",
    "    This class just records a 'column number' (e.g., 0 for Color) and a\n",
    "    'column value' (e.g., Green). The 'match' method is used to compare\n",
    "    the feature value in an example to the feature value stored in the\n",
    "    question. See the demo below.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    def match(self, example):\n",
    "        # Compare the feature value in an example to the\n",
    "        # feature value in this question.\n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            header[self.column], condition, str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Is Type == b'engineer'?"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question(0, b'engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition(rows, question):\n",
    "    \"\"\"Partitions a dataset.\n",
    "\n",
    "    For each row in the dataset, check if it matches the question. If\n",
    "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
    "    \"\"\"\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_rows, false_rows = partition(training_data, Question(0, b'engineer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'engineer', b'spend>saving', 23.0, 86.0, 20.04, 1.351, b'C1'],\n",
       " [b'engineer', b'spend>saving', 20.0, 69.0, 19.69, 7.0714, b'C1'],\n",
       " [b'engineer', b'spend>saving', 14.0, 86.0, 20.23, 7.4749, b'C1'],\n",
       " [b'engineer', b'spend>saving', 41.0, 50.0, 21.0, 6.8701, b'C1'],\n",
       " [b'engineer', b'spend>saving', 17.0, 38.0, 21.22, 1.0881, b'C1'],\n",
       " [b'engineer', b'spend>saving', 6.0, 76.0, 19.46, 3.1729, b'C1'],\n",
       " [b'engineer', b'spend>saving', 38.0, 61.0, 20.91, 3.2021, b'C1'],\n",
       " [b'engineer', b'spend>saving', 23.0, 45.0, 19.83, 4.215, b'C1'],\n",
       " [b'engineer', b'spend>saving', 9.0, 58.0, 19.66, 2.4553, b'C1'],\n",
       " [b'engineer', b'spend>>saving', 46.0, 20.0, 20.54, 1.6447, b'C1'],\n",
       " [b'engineer', b'spend>>saving', 53.0, 82.0, 20.93, 2.7064, b'C1'],\n",
       " [b'engineer', b'spend>>saving', 31.0, 40.0, 19.43, 5.7642, b'C1'],\n",
       " [b'engineer', b'spend>>saving', 41.0, 46.0, 18.5, 8.3453, b'C1'],\n",
       " [b'engineer', b'spend<<saving', 39.0, 87.0, 19.95, 4.0586, b'C1'],\n",
       " [b'engineer', b'spend<<saving', 28.0, 42.0, 20.55, 3.0668, b'C1'],\n",
       " [b'engineer', b'spend<<saving', 52.0, 52.0, 20.08, 5.0033, b'C1'],\n",
       " [b'engineer', b'spend<<saving', 40.0, 50.0, 21.58, 2.6248, b'C1'],\n",
       " [b'engineer', b'spend<<saving', 45.0, 92.0, 19.67, 7.325, b'C1'],\n",
       " [b'engineer', b'spend<<saving', 33.0, 62.0, 20.8, 5.8137, b'C1'],\n",
       " [b'engineer', b'spend>>saving', 39.0, 62.0, 19.16, 3.9847, b'C4'],\n",
       " [b'engineer', b'spend<<saving', 43.0, 69.0, 20.28, 3.5298, b'C4'],\n",
       " [b'engineer', b'spend>>saving', 50.0, 55.0, 20.82, 3.0217, b'C4'],\n",
       " [b'engineer', b'spend<<saving', 26.0, 49.0, 21.23, 4.0693, b'C4'],\n",
       " [b'engineer', b'spend>>saving', 30.0, 44.0, 19.94, 4.8997, b'C4'],\n",
       " [b'engineer', b'spend<<saving', 34.0, 72.0, 20.65, 5.2348, b'C4'],\n",
       " [b'engineer', b'spend>saving', 42.0, 65.0, 18.23, 2.8972, b'C4'],\n",
       " [b'engineer', b'spend<saving', 53.0, 76.0, 20.06, 4.4073, b'C4'],\n",
       " [b'engineer', b'spend>saving', 59.0, 55.0, 19.24, 2.5725, b'C4'],\n",
       " [b'engineer', b'spend<saving', 47.0, 70.0, 18.31, 4.8945, b'C4'],\n",
       " [b'engineer', b'spend>>saving', 48.0, 63.0, 21.1, 3.6149, b'C4'],\n",
       " [b'engineer', b'spend<<saving', 39.0, 51.0, 21.46, 3.8187, b'C4'],\n",
       " [b'engineer', b'spend>saving', 50.0, 18.0, 24.01, 0.738, b'C5'],\n",
       " [b'engineer', b'spend>saving', 50.0, 18.0, 21.52, 1.6871, b'C5'],\n",
       " [b'engineer', b'spend>saving', 51.0, 22.0, 21.99, 1.358, b'C5'],\n",
       " [b'engineer', b'spend>saving', 49.0, 22.0, 20.27, 1.2342, b'C5'],\n",
       " [b'engineer', b'spend>saving', 50.0, 22.0, 21.22, 0.534, b'C5'],\n",
       " [b'engineer', b'spend>saving', 51.0, 26.0, 25.94, 0.6948, b'C5'],\n",
       " [b'engineer', b'spend>saving', 50.0, 24.0, 23.87, 1.5738, b'C5'],\n",
       " [b'engineer', b'spend>saving', 52.0, 14.0, 16.54, 1.5569, b'C5'],\n",
       " [b'engineer', b'spend>saving', 50.0, 22.0, 23.09, 1.0051, b'C5'],\n",
       " [b'engineer', b'spend>>saving', 49.0, 21.0, 23.89, 1.5087, b'C5'],\n",
       " [b'engineer', b'spend>>saving', 51.0, 20.0, 13.68, 1.5669, b'C5'],\n",
       " [b'engineer', b'spend>>saving', 49.0, 17.0, 18.79, 2.0525, b'C5'],\n",
       " [b'engineer', b'spend>>saving', 50.0, 23.0, 20.17, 2.3291, b'C5'],\n",
       " [b'engineer', b'spend>>saving', 47.0, 23.0, 22.78, 1.041, b'C5'],\n",
       " [b'engineer', b'spend>>saving', 51.0, 23.0, 25.56, 2.5066, b'C5'],\n",
       " [b'engineer', b'spend>>saving', 51.0, 17.0, 15.63, 1.6754, b'C5'],\n",
       " [b'engineer', b'spend>>saving', 51.0, 13.0, 20.71, 1.4585, b'C5'],\n",
       " [b'engineer', b'spend>>saving', 49.0, 17.0, 19.18, 2.4251, b'C5']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'student', b'spend>saving', 6.0, 40.0, 13.62, 3.2804, b'C1'],\n",
       " [b'student', b'spend>saving', 11.0, 21.0, 15.32, 2.0232, b'C1'],\n",
       " [b'student', b'spend>saving', 7.0, 64.0, 16.55, 3.1202, b'C1'],\n",
       " [b'student', b'spend>saving', 3.0, 47.0, 15.71, 3.4022, b'C1'],\n",
       " [b'student', b'spend>saving', 15.0, 10.0, 16.96, 2.2825, b'C1'],\n",
       " [b'student', b'spend>saving', 6.0, 80.0, 15.5, 3.7338, b'C1'],\n",
       " [b'student', b'spend<saving', 10.0, 49.0, 16.86, 5.8639, b'C1'],\n",
       " [b'student', b'spend<saving', 10.0, 84.0, 14.66, 3.187, b'C1'],\n",
       " [b'student', b'spend<saving', 9.0, 74.0, 13.86, 2.3823, b'C1'],\n",
       " [b'student', b'spend>>saving', 22.0, 38.0, 13.88, 0.7394, b'C1'],\n",
       " [b'student', b'spend>>saving', 25.0, 30.0, 15.64, 3.1282, b'C1'],\n",
       " [b'student', b'spend>>saving', 31.0, 15.0, 14.4, 2.3925, b'C1'],\n",
       " [b'student', b'spend>>saving', 24.0, 55.0, 15.55, 1.9857, b'C1'],\n",
       " [b'student', b'spend>>saving', 28.0, 85.0, 13.9, 4.3147, b'C1'],\n",
       " [b'student', b'spend<<saving', 25.0, 24.0, 15.09, 5.1951, b'C1'],\n",
       " [b'student', b'spend<<saving', 24.0, 15.0, 13.0, 1.6162, b'C1'],\n",
       " [b'student', b'spend<<saving', 25.0, 33.0, 14.51, 2.5551, b'C1'],\n",
       " [b'librarian', b'spend>saving', 7.0, 10.0, 18.1751, 1.2225, b'C2'],\n",
       " [b'librarian', b'spend>saving', 1.0, 3.0, 16.4385, 0.9869, b'C2'],\n",
       " [b'librarian', b'spend>saving', 2.0, 8.0, 12.4786, 0.7506, b'C2'],\n",
       " [b'librarian', b'spend>saving', 7.0, 11.0, 15.8298, 0.5672, b'C2'],\n",
       " [b'librarian', b'spend>saving', 5.0, 11.0, 14.6699, 1.0147, b'C2'],\n",
       " [b'librarian', b'spend<saving', 7.0, 11.0, 13.4146, 0.1724, b'C2'],\n",
       " [b'librarian', b'spend<saving', 9.0, 10.0, 17.9944, 0.2708, b'C2'],\n",
       " [b'librarian', b'spend<saving', 6.0, 5.0, 11.0413, 1.7063, b'C2'],\n",
       " [b'librarian', b'spend<saving', 3.0, 11.0, 18.254, 0.8712, b'C2'],\n",
       " [b'librarian', b'spend<saving', 7.0, 10.0, 8.8997, 1.9516, b'C2'],\n",
       " [b'librarian', b'spend<saving', 4.0, 11.0, 19.116, 0.8027, b'C2'],\n",
       " [b'librarian', b'spend<saving', 3.0, 12.0, 18.3739, 0.9693, b'C2'],\n",
       " [b'librarian', b'spend>saving', 11.0, 10.0, 20.0328, 1.2693, b'C2'],\n",
       " [b'librarian', b'spend>saving', 5.0, 11.0, 14.2322, 0.8286, b'C2'],\n",
       " [b'professor', b'spend>saving', 10.0, 9.0, 20.5991, 0.552, b'C2'],\n",
       " [b'professor', b'spend>saving', 7.0, 7.0, 8.5076, 1.223, b'C2'],\n",
       " [b'professor', b'spend>saving', 7.0, 11.0, 18.1388, 0.6957, b'C2'],\n",
       " [b'professor', b'spend>saving', 5.0, 14.0, 14.0667, 1.1974, b'C2'],\n",
       " [b'professor', b'spend>saving', 5.0, 8.0, 13.9065, 1.2392, b'C2'],\n",
       " [b'professor', b'spend>saving', 8.0, 8.0, 17.6074, 0.568, b'C2'],\n",
       " [b'professor', b'spend>saving', 4.0, 12.0, 15.6526, 1.1132, b'C2'],\n",
       " [b'professor', b'spend<saving', 3.0, 5.0, 21.054, 1.0448, b'C2'],\n",
       " [b'professor', b'spend<saving', 4.0, 7.0, 15.0986, 0.8853, b'C2'],\n",
       " [b'professor', b'spend<saving', 1.0, 8.0, 17.2758, 0.4089, b'C2'],\n",
       " [b'professor', b'spend<saving', 6.0, 17.0, 18.5944, 0.79, b'C2'],\n",
       " [b'professor', b'spend<saving', 5.0, 11.0, 21.4653, 0.8358, b'C2'],\n",
       " [b'student', b'spend<saving', 6.0, 73.0, 31.75, 4.8256, b'C3'],\n",
       " [b'student', b'spend<saving', 11.0, 71.0, 26.31, 3.4024, b'C3'],\n",
       " [b'student', b'spend<saving', 11.0, 70.0, 27.86, 3.8865, b'C3'],\n",
       " [b'student', b'spend<saving', 7.0, 66.0, 31.39, 3.5978, b'C3'],\n",
       " [b'student', b'spend<saving', 9.0, 69.0, 16.74, 5.4591, b'C3'],\n",
       " [b'student', b'spend<saving', 14.0, 70.0, 22.03, 5.0585, b'C3'],\n",
       " [b'student', b'spend>saving', 12.0, 68.0, 22.79, 4.7536, b'C3'],\n",
       " [b'student', b'spend>saving', 13.0, 72.0, 26.19, 2.6436, b'C3'],\n",
       " [b'student', b'spend>saving', 10.0, 66.0, 20.09, 3.9933, b'C3'],\n",
       " [b'student', b'spend>saving', 5.0, 68.0, 24.24, 3.7744, b'C3'],\n",
       " [b'student', b'spend>saving', 5.0, 71.0, 23.79, 4.6938, b'C3'],\n",
       " [b'student', b'spend>saving', 11.0, 75.0, 28.83, 3.3291, b'C3'],\n",
       " [b'student', b'spend>saving', 8.0, 67.0, 22.87, 4.2798, b'C3'],\n",
       " [b'doctor', b'spend>saving', 12.0, 261.0, 23.07, 12.8549, b'C3'],\n",
       " [b'doctor', b'spend>saving', 6.0, 279.0, 26.98, 8.0012, b'C3'],\n",
       " [b'doctor', b'spend>saving', 11.0, 96.0, 28.88, 9.8281, b'C3'],\n",
       " [b'doctor', b'spend>saving', 12.0, 347.0, 25.94, 10.0092, b'C3'],\n",
       " [b'doctor', b'spend>saving', 11.0, 268.0, 27.58, 12.5953, b'C3'],\n",
       " [b'doctor', b'spend>saving', 7.0, 253.0, 25.39, 6.6154, b'C3'],\n",
       " [b'doctor', b'spend>saving', 9.0, 162.0, 25.05, 7.837, b'C3'],\n",
       " [b'doctor', b'spend>saving', 11.0, 187.0, 24.78, 12.5933, b'C3'],\n",
       " [b'doctor', b'spend>saving', 5.0, 131.0, 22.02, 16.408, b'C3'],\n",
       " [b'doctor', b'spend>saving', 8.0, 137.0, 22.76, 13.0995, b'C3'],\n",
       " [b'doctor', b'spend>saving', 7.0, 155.0, 24.91, 10.6717, b'C3'],\n",
       " [b'doctor', b'spend>saving', 13.0, 229.0, 27.97, 11.8543, b'C3'],\n",
       " [b'doctor', b'spend>saving', 15.0, 292.0, 23.2, 12.2331, b'C3'],\n",
       " [b'doctor', b'spend>saving', 12.0, 267.0, 29.43, 17.8737, b'C3'],\n",
       " [b'doctor', b'spend>saving', 8.0, 175.0, 22.56, 11.7815, b'C3'],\n",
       " [b'doctor', b'spend>saving', 11.0, 91.0, 26.94, 14.8164, b'C3'],\n",
       " [b'doctor', b'spend>saving', 9.0, 212.0, 21.07, 11.7612, b'C3'],\n",
       " [b'doctor', b'spend>saving', 7.0, 163.0, 22.4, 9.5971, b'C3'],\n",
       " [b'doctor', b'spend>saving', 11.0, 111.0, 23.58, 12.9283, b'C3'],\n",
       " [b'doctor', b'spend>saving', 10.0, 222.0, 25.67, 15.1555, b'C3'],\n",
       " [b'doctor', b'spend<saving', 9.0, 187.0, 23.77, 11.4248, b'C3'],\n",
       " [b'doctor', b'spend<saving', 12.0, 179.0, 26.53, 13.3902, b'C3'],\n",
       " [b'doctor', b'spend<saving', 6.0, 190.0, 21.4, 9.2276, b'C3'],\n",
       " [b'doctor', b'spend<saving', 8.0, 191.0, 24.71, 10.051, b'C3'],\n",
       " [b'doctor', b'spend<saving', 9.0, 211.0, 26.34, 13.8687, b'C3'],\n",
       " [b'doctor', b'spend<saving', 13.0, 284.0, 24.11, 7.9947, b'C3'],\n",
       " [b'doctor', b'spend<saving', 15.0, 206.0, 24.5, 15.1431, b'C3'],\n",
       " [b'doctor', b'spend<saving', 14.0, 233.0, 25.54, 14.59, b'C3'],\n",
       " [b'doctor', b'spend<saving', 47.0, 51.0, 18.45, 5.6494, b'C4'],\n",
       " [b'doctor', b'spend<saving', 42.0, 66.0, 19.61, 4.202, b'C4'],\n",
       " [b'doctor', b'spend>saving', 40.0, 78.0, 20.28, 3.6179, b'C4'],\n",
       " [b'doctor', b'spend>saving', 40.0, 61.0, 20.83, 1.9896, b'C4'],\n",
       " [b'doctor', b'spend>saving', 34.0, 86.0, 19.02, 4.8388, b'C4'],\n",
       " [b'doctor', b'spend<saving', 59.0, 53.0, 19.9, 4.2836, b'C4'],\n",
       " [b'doctor', b'spend<saving', 38.0, 88.0, 20.13, 2.8193, b'C4'],\n",
       " [b'doctor', b'spend>saving', 26.0, 60.0, 20.06, 4.131, b'C4'],\n",
       " [b'doctor', b'spend>saving', 37.0, 63.0, 20.37, 5.7345, b'C4'],\n",
       " [b'student', b'spend>>saving', 32.0, 66.0, 20.02, 3.5865, b'C4'],\n",
       " [b'student', b'spend<<saving', 23.0, 68.0, 21.37, 2.2667, b'C4'],\n",
       " [b'student', b'spend>saving', 36.0, 43.0, 20.42, 3.0437, b'C4'],\n",
       " [b'student', b'spend<saving', 25.0, 41.0, 20.07, 4.3556, b'C4'],\n",
       " [b'student', b'spend>saving', 39.0, 56.0, 20.29, 2.6881, b'C4'],\n",
       " [b'student', b'spend<saving', 49.0, 60.0, 20.47, 4.9717, b'C4'],\n",
       " [b'student', b'spend>>saving', 64.0, 84.0, 21.78, 3.8456, b'C4'],\n",
       " [b'student', b'spend<<saving', 45.0, 57.0, 20.26, 3.7188, b'C4'],\n",
       " [b'professor', b'spend>>saving', 44.0, 44.0, 21.51, 2.6675, b'C4'],\n",
       " [b'professor', b'spend<<saving', 51.0, 16.0, 20.32, 2.1608, b'C4'],\n",
       " [b'professor', b'spend>>saving', 44.0, 39.0, 20.8, 1.7196, b'C4'],\n",
       " [b'professor', b'spend<<saving', 53.0, 35.0, 20.58, 2.5493, b'C4'],\n",
       " [b'professor', b'spend>saving', 38.0, 25.0, 21.78, 0.008, b'C4'],\n",
       " [b'professor', b'spend<saving', 41.0, 54.0, 19.06, 3.0132, b'C4'],\n",
       " [b'professor', b'spend>saving', 33.0, 50.0, 19.08, 1.7395, b'C4'],\n",
       " [b'professor', b'spend<saving', 32.0, 38.0, 20.38, 1.4075, b'C4'],\n",
       " [b'professor', b'spend>>saving', 34.0, 30.0, 20.91, 2.4095, b'C4'],\n",
       " [b'librarian', b'spend<<saving', 48.0, 35.0, 20.15, 2.4436, b'C4'],\n",
       " [b'librarian', b'spend>>saving', 41.0, 37.0, 19.8, 2.8195, b'C4'],\n",
       " [b'librarian', b'spend<<saving', 22.0, 24.0, 21.49, 2.7344, b'C4'],\n",
       " [b'librarian', b'spend>>saving', 58.0, 27.0, 19.38, 3.0286, b'C4'],\n",
       " [b'librarian', b'spend<<saving', 47.0, 45.0, 20.81, 1.5505, b'C4'],\n",
       " [b'librarian', b'spend>saving', 25.0, 40.0, 21.93, 1.0924, b'C4'],\n",
       " [b'librarian', b'spend<saving', 36.0, 33.0, 20.4, 1.2062, b'C4'],\n",
       " [b'librarian', b'spend>saving', 42.0, 22.0, 19.14, 1.5377, b'C4'],\n",
       " [b'librarian', b'spend<saving', 32.0, 25.0, 22.43, 3.0428, b'C4'],\n",
       " [b'professor', b'spend>saving', 48.0, 5.0, 20.39, 1.7536, b'C5'],\n",
       " [b'professor', b'spend>saving', 51.0, 5.0, 27.6, 2.4567, b'C5'],\n",
       " [b'professor', b'spend>saving', 50.0, 3.0, 23.12, 2.4937, b'C5'],\n",
       " [b'professor', b'spend>saving', 51.0, 3.0, 29.52, 2.3271, b'C5'],\n",
       " [b'professor', b'spend>saving', 50.0, 4.0, 18.8, 2.9932, b'C5'],\n",
       " [b'professor', b'spend>saving', 50.0, 6.0, 19.76, 2.8216, b'C5'],\n",
       " [b'professor', b'spend>saving', 49.0, 7.0, 28.84, 3.96, b'C5'],\n",
       " [b'professor', b'spend>saving', 49.0, 5.0, 19.42, 1.8757, b'C5'],\n",
       " [b'professor', b'spend>saving', 50.0, 3.0, 16.31, 2.5786, b'C5'],\n",
       " [b'professor', b'spend>>saving', 49.0, 5.0, 23.51, 2.7638, b'C5'],\n",
       " [b'professor', b'spend>>saving', 50.0, 5.0, 22.71, 3.3358, b'C5'],\n",
       " [b'professor', b'spend>>saving', 50.0, 3.0, 19.59, 2.9, b'C5'],\n",
       " [b'professor', b'spend>>saving', 50.0, 3.0, 18.03, 2.9419, b'C5'],\n",
       " [b'professor', b'spend>>saving', 51.0, 6.0, 26.76, 2.3879, b'C5'],\n",
       " [b'professor', b'spend>>saving', 49.0, 5.0, 31.55, 2.6485, b'C5'],\n",
       " [b'professor', b'spend>>saving', 49.0, 3.0, 31.06, 2.2395, b'C5'],\n",
       " [b'professor', b'spend>>saving', 50.0, 5.0, 31.2, 2.4223, b'C5'],\n",
       " [b'professor', b'spend>>saving', 50.0, 4.0, 20.92, 2.4508, b'C5']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "    \"\"\"Calculate the Gini Impurity for a list of rows.\n",
    "\n",
    "    There are a few different ways to do this, I thought this one was\n",
    "    the most concise. See:\n",
    "    https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "    \"\"\"\n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999999999999998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lots_of_mixing = [['Apple'],\n",
    "                  ['Orange'],\n",
    "                  ['Grape'],\n",
    "                  ['Grapefruit'],\n",
    "                  ['Blueberry']]\n",
    "\n",
    "gini(lots_of_mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainty):\n",
    "    \"\"\"Information Gain.\n",
    "\n",
    "    The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nodes.\n",
    "    \"\"\"\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - p * gini(left) - (1 - p) * gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.793097467915366"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_uncertainty = gini(training_data)\n",
    "current_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03543445685676927"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rows, false_rows = partition(training_data, Question(0, b'student'))\n",
    "info_gain(true_rows, false_rows, current_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048682442663447456"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rows, false_rows = partition(training_data, Question(0, b'engineer'))\n",
    "info_gain(true_rows, false_rows, current_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
    "    and calculating the information gain.\"\"\"\n",
    "    best_gain = 0  # keep track of the best information gain\n",
    "    best_question = None  # keep train of the feature / value that produced it\n",
    "    current_uncertainty = gini(rows)\n",
    "    n_features = len(rows[0]) - 1  # number of columns\n",
    "\n",
    "    for col in range(n_features):  # for each feature\n",
    "\n",
    "        values = set([row[col] for row in rows])  # unique values in the column\n",
    "\n",
    "        for val in values:  # for each value\n",
    "\n",
    "            question = Question(col, val)\n",
    "\n",
    "            # try splitting the dataset\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "            # Skip this split if it doesn't divide the\n",
    "            # dataset.\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate the information gain from this split\n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
    "\n",
    "            # You actually can use '>' instead of '>=' here\n",
    "            # but I wanted the tree to look a certain way for our\n",
    "            # toy dataset.\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Is Vacation >= 17.0?"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gain, best_question = find_best_split(training_data)\n",
    "best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \"\"\"A Leaf node classifies data.\n",
    "\n",
    "    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
    "    it appears in the rows from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Decision_Node:\n",
    "    \"\"\"A Decision Node asks a question.\n",
    "\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    \"\"\"Builds the tree.\n",
    "\n",
    "    Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
    "    for the base case (no further information gain). 3) Prepare for\n",
    "    giant stack traces.\n",
    "    \"\"\"\n",
    "\n",
    "    # Try partitioing the dataset on each of the unique attribute,\n",
    "    # calculate the information gain,\n",
    "    # and return the question that produces the highest gain.\n",
    "    gain, question = find_best_split(rows)\n",
    "\n",
    "    # Base case: no further info gain\n",
    "    # Since we can ask no further questions,\n",
    "    # we'll return a leaf.\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "\n",
    "    # If we reach here, we have found a useful feature / value\n",
    "    # to partition on.\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "    # Recursively build the true branch.\n",
    "    true_branch = build_tree(true_rows)\n",
    "\n",
    "    # Recursively build the false branch.\n",
    "    false_branch = build_tree(false_rows)\n",
    "\n",
    "    # Return a Question node.\n",
    "    # This records the best feature / value to ask at this point,\n",
    "    # as well as the branches to follow\n",
    "    # dependingo on the answer.\n",
    "    return Decision_Node(question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    \"\"\"World's most elegant tree printing function.\"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        print (spacing + \"Predict\", node.predictions)\n",
    "        return\n",
    "\n",
    "    # Print the question at this node\n",
    "    print (spacing + str(node.question))\n",
    "\n",
    "    # Call this function recursively on the true branch\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Call this function recursively on the false branch\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_tree = build_tree(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Vacation >= 17.0?\n",
      "--> True:\n",
      "  Is eCredit >= 24.0?\n",
      "  --> True:\n",
      "    Is Property >= 5.7642?\n",
      "    --> True:\n",
      "      Predict {b'C1': 6}\n",
      "    --> False:\n",
      "      Is Salary >= 18.23?\n",
      "      --> True:\n",
      "        Is Type == b'engineer'?\n",
      "        --> True:\n",
      "          Is eCredit >= 38.0?\n",
      "          --> True:\n",
      "            Is Vacation >= 26.0?\n",
      "            --> True:\n",
      "              Is eCredit >= 82.0?\n",
      "              --> True:\n",
      "                Predict {b'C1': 2}\n",
      "              --> False:\n",
      "                Is eCredit >= 62.0?\n",
      "                --> True:\n",
      "                  Predict {b'C4': 7}\n",
      "                --> False:\n",
      "                  Is Salary >= 20.08?\n",
      "                  --> True:\n",
      "                    Is Salary >= 20.82?\n",
      "                    --> True:\n",
      "                      Is Property >= 3.8187?\n",
      "                      --> True:\n",
      "                        Predict {b'C4': 2}\n",
      "                      --> False:\n",
      "                        Is Salary >= 20.91?\n",
      "                        --> True:\n",
      "                          Predict {b'C1': 2}\n",
      "                        --> False:\n",
      "                          Predict {b'C4': 1}\n",
      "                    --> False:\n",
      "                      Predict {b'C1': 2}\n",
      "                  --> False:\n",
      "                    Predict {b'C4': 2}\n",
      "            --> False:\n",
      "              Predict {b'C1': 3}\n",
      "          --> False:\n",
      "            Predict {b'C5': 2}\n",
      "        --> False:\n",
      "          Predict {b'C4': 33}\n",
      "      --> False:\n",
      "        Predict {b'C1': 6}\n",
      "  --> False:\n",
      "    Is Vacation >= 47.0?\n",
      "    --> True:\n",
      "      Is LifeStyle == b'spend<<saving'?\n",
      "      --> True:\n",
      "        Predict {b'C4': 1}\n",
      "      --> False:\n",
      "        Predict {b'C5': 34}\n",
      "    --> False:\n",
      "      Is Property >= 1.6162?\n",
      "      --> True:\n",
      "        Predict {b'C1': 3}\n",
      "      --> False:\n",
      "        Predict {b'C4': 1}\n",
      "--> False:\n",
      "  Is Property >= 2.0232?\n",
      "  --> True:\n",
      "    Is Salary >= 21.07?\n",
      "    --> True:\n",
      "      Predict {b'C3': 39}\n",
      "    --> False:\n",
      "      Is Property >= 3.9933?\n",
      "      --> True:\n",
      "        Is Property >= 5.8639?\n",
      "        --> True:\n",
      "          Predict {b'C1': 2}\n",
      "        --> False:\n",
      "          Predict {b'C3': 2}\n",
      "      --> False:\n",
      "        Predict {b'C1': 10}\n",
      "  --> False:\n",
      "    Predict {b'C2': 26}\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "\n",
    "    # Decide whether to follow the true-branch or the false-branch.\n",
    "    # Compare the feature / value stored in the node,\n",
    "    # to the example we're considering.\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'C1': 10}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(training_data[0], my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_leaf(counts):\n",
    "    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'C1': '100%'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_leaf(classify(training_data[0], my_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'C1': '100%'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_leaf(classify(training_data[28], my_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset1 = arff.loadarff('testProdSelection.arff')\n",
    "df1 = pd.DataFrame(dataset1[0])\n",
    "nparray1 = df1.values \n",
    "testing_data=[]\n",
    "testing_data=nparray1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'student', b'spend<saving', 12.0, 19.0, 14.79, 3.7697, b'C1'],\n",
       " [b'student', b'spend>>saving', 29.0, 10.0, 16.19, 2.4839, b'C1'],\n",
       " [b'student', b'spend<<saving', 28.0, 60.0, 15.46, 1.1885, b'C1'],\n",
       " [b'engineer', b'spend>saving', 15.0, 41.0, 21.26, 1.4379, b'C1'],\n",
       " [b'librarian', b'spend<saving', 2.0, 9.0, 19.7207, 0.6913, b'C1'],\n",
       " [b'librarian', b'spend>saving', 7.0, 9.0, 12.7098, 1.4728, b'C1'],\n",
       " [b'professor', b'spend>saving', 5.0, 10.0, 20.883, 1.3131, b'C1'],\n",
       " [b'professor', b'spend<saving', 3.0, 15.0, 16.5711, 0.4792, b'C1'],\n",
       " [b'student', b'spend<saving', 9.0, 71.0, 25.7, 2.0947, b'C1'],\n",
       " [b'student', b'spend>saving', 10.0, 67.0, 27.11, 3.8391, b'C1'],\n",
       " [b'doctor', b'spend>saving', 7.0, 229.0, 30.61, 7.0074, b'C1'],\n",
       " [b'doctor', b'spend<saving', 8.0, 243.0, 25.33, 8.7276, b'C1'],\n",
       " [b'professor', b'spend>saving', 51.0, 5.0, 18.98, 2.8944, b'C1'],\n",
       " [b'doctor', b'spend>saving', 34.0, 51.0, 19.9, 3.9544, b'C1'],\n",
       " [b'student', b'spend>>saving', 39.0, 40.0, 19.3, 3.8317, b'C1'],\n",
       " [b'student', b'spend>>saving', 36.0, 57.0, 19.61, 4.888, b'C1'],\n",
       " [b'professor', b'spend>>saving', 34.0, 30.0, 20.91, 2.4095, b'C1'],\n",
       " [b'librarian', b'spend>>saving', 48.0, 35.0, 20.15, 2.4436, b'C1'],\n",
       " [b'professor', b'spend>>saving', 52.0, 5.0, 22.63, 2.2115, b'C1'],\n",
       " [b'engineer', b'spend>saving', 50.0, 17.0, 32.59, 1.2229, b'C1'],\n",
       " [b'engineer', b'spend>>saving', 50.0, 15.0, 21.78, 2.07, b'C1']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Predicted: {b'C1': '100%'}\n",
      " Predicted: {b'C1': '100%'}\n",
      " Predicted: {b'C1': '100%'}\n",
      " Predicted: {b'C2': '100%'}\n",
      " Predicted: {b'C2': '100%'}\n",
      " Predicted: {b'C2': '100%'}\n",
      " Predicted: {b'C2': '100%'}\n",
      " Predicted: {b'C2': '100%'}\n",
      " Predicted: {b'C3': '100%'}\n",
      " Predicted: {b'C3': '100%'}\n",
      " Predicted: {b'C3': '100%'}\n",
      " Predicted: {b'C3': '100%'}\n",
      " Predicted: {b'C5': '100%'}\n",
      " Predicted: {b'C4': '100%'}\n",
      " Predicted: {b'C4': '100%'}\n",
      " Predicted: {b'C4': '100%'}\n",
      " Predicted: {b'C4': '100%'}\n",
      " Predicted: {b'C4': '100%'}\n",
      " Predicted: {b'C5': '100%'}\n",
      " Predicted: {b'C5': '100%'}\n",
      " Predicted: {b'C5': '100%'}\n"
     ]
    }
   ],
   "source": [
    "for row in testing_data:\n",
    "    print (\" Predicted: %s\" %\n",
    "           ( print_leaf(classify(row, my_tree))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
